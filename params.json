{"name":"Spidey","tagline":"[WIP] Web Crawler in Node.js to spider dynamically whole websites.","body":"# SPIDEY\r\n\r\n[![Build Status](https://travis-ci.org/fabiocicerchia/spidey.png)](https://travis-ci.org/fabiocicerchia/spidey)\r\n[![Dependency Status](https://gemnasium.com/fabiocicerchia/spidey.png)](https://gemnasium.com/fabiocicerchia/spidey)\r\n[![Coverage Status](https://coveralls.io/repos/fabiocicerchia/spidey/badge.png)](https://coveralls.io/r/fabiocicerchia/spidey)\r\n\r\n[![NPM](https://nodei.co/npm/spidey.png?downloads=true&stars=true)](https://nodei.co/npm/spidey/)\r\n\r\n[![Spidey - Web Crawler in Node.js to spider dynamically whole websites.](http://jpillora.com/github-twitter-button/img/tweet.png)](https://twitter.com/intent/tweet?text=Spidey+-+Web+Crawler+in+Node.js+to+spider+dynamically+whole+websites.&url=https%3A%2F%2Fgithub.com%2Ffabiocicerchia%2Fspidey&hashtags=spidey&original_referer=http%3A%2F%2Fgithub.com%2F&tw_p=tweetbutton)\r\n\r\nWeb Crawler in Node.js to spider dynamically whole websites.\r\n\r\nIt helps you to map / process entire websites, spidering them and parsing each\r\npage in a smart way. It follows all the links and test several times the form\r\nobjects. In this way is possible to check effectively the whole website.\r\n\r\nFew suggestion about its usage:\r\n\r\n * Improve the legacy code\r\n  * Check the dead code (enabling the code coverage server-side)\r\n  * Discover 500 Internal Server Errors\r\n  * Discover notices and warnings\r\n * Testing\r\n  * Process forms (it'll create easy test cases to be manually compiled)\r\n  * Process automatically JS events attached to DOM nodes\r\n * Scraping\r\n  * Get the page content for each URL\r\n  * Get the screenshot for each URL\r\n * Enumeration\r\n  * URLs list\r\n  * Execution times\r\n  * Page output\r\n  * Page load\r\n * ...\r\n\r\n## Features\r\n\r\n * Command Line Interface\r\n * Reorder query string params for get and post for uniqueness\r\n * HTTP authentication\r\n * Handle events bound with `addEventListener`, HTML attributes (`on*`)\r\n * Exclude external URIs in the crawling\r\n * Process the page using PhantomJS\r\n * Generate report for each page crawled\r\n  * Screenshot\r\n  * HTTP header\r\n  * HTTP method\r\n  * Data sent\r\n  * Page output\r\n  * Execution time\r\n  * Console messages\r\n  * Alerts, Confirmations & Prompts\r\n  * Errors\r\n  * List of requests\r\n\r\n## Dependencies\r\n\r\nHere the list of main dependencies:\r\n\r\n * [Node.js](http://nodejs.org/download/)\r\n * [PhantomJS](http://phantomjs.org/download.html) / [CasperJS](http://casperjs.org/)\r\n * [Redis](http://redis.io/download)\r\n\r\n## Installation\r\n\r\nYou can install it directly from npm:\r\n\r\n```\r\n[user@hostname ~]$ npm install spidey -g\r\n```\r\n\r\nor you can download the source code from GitHub and run these commands:\r\n\r\n```\r\n[user@hostname ~/spidey]$ npm install\r\n```\r\n\r\n## Configuration\r\n\r\nChange the file `src/config.js` accordingly to your needs.\r\n\r\n## Usage\r\n\r\n```\r\n              __     __\r\n.-----.-----.|__|.--|  |.-----.--.--.\r\n|__ --|  _  ||  ||  _  ||  -__|  |  |\r\n|_____|   __||__||_____||_____|___  |\r\n      |__|                    |_____|\r\n\r\nSPIDEY v0.2.0\r\n\r\nCopyright (C) 2013 Fabio Cicerchia <info@fabiocicerchia.it>\r\n\r\nWeb Crawler in Node.js to spider dynamically whole websites.\r\nUsage: ./bin/spidey\r\n\r\nOptions:\r\n  --uri              The URI to be crawled             [required]\r\n  -u, --username     Username for HTTP authentication\r\n  -p, --password     Password for HTTP authentication\r\n  -d, --details      Store details for each page       [default: false]\r\n  --help             Show the help\r\n```\r\n\r\n## Examples\r\n\r\n```\r\n[user@hostname ~]$ spidey --uri \"http://www.google.com\"\r\n[user@hostname ~]$ spidey --uri \"www.google.com\"\r\n[user@hostname ~]$ spidey --uri \"/tmp/file.html\"\r\n[user@hostname ~]$ spidey --uri \"file.html\"\r\n```\r\n\r\n## Tests\r\n\r\n```\r\n[user@hostname ~/spidey]$ npm test\r\n```\r\n\r\n## Bugs\r\n\r\nFor a list of bugs please go to the [GitHub Issue Page](https://github.com/fabiocicerchia/spidey/issues?labels=Bug&page=1&state=open).\r\n\r\n## Licence\r\n\r\nCopyright (C) 2013 Fabio Cicerchia <info@fabiocicerchia.it>\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy of\r\nthis software and associated documentation files (the \"Software\"), to deal in\r\nthe Software without restriction, including without limitation the rights to\r\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\r\nthe Software, and to permit persons to whom the Software is furnished to do so,\r\nsubject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in all\r\ncopies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\r\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\r\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\r\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\r\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}